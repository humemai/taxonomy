{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data overview\n",
    "\n",
    "From the `*.log` files that as of 09-Feb-2025, you can see:\n",
    "\n",
    "- Total entities: 113,721,673\n",
    "- Total entities that have English labels: 88,923,509\n",
    "- Total properties: 12,397\n",
    "- Ony 90,816 entities (classes) have instances in Wikidata, which is about 0.079% of the total entities.\n",
    "- ![](./process_p31_p279/classes_cumulative_distribution.png)\n",
    "- Above image shows that even among 90,816 entities, there few entities have most of the instances.\n",
    "- There are 4,932,987 (a, subclass_of, b) relationships we can find.\n",
    "- 4,201,747 child entities have parent entities through subclass_of (P279). This is lower than 4,932,987, since one child entity can have multiple parent entities\n",
    "- Out of 4,201,747 child entities, 666,843 have multiple parent entities (P279), which violates the hierarchical tree structure. What is worse than from child-to-parent realtionships we can find 4,831,313 cycles using DFS!\n",
    "- There are 121,437,570 (a, instance_of, b) relationships we can find through P31. This is a bigger number that that of P279. The wikidata users are more likely to write about instance_of relationships than subclass_of relationships.\n",
    "- 96,392,021 entities have English descriptions. This is kinda odd cuz it means that there are more entities with English labels than English descriptions. I'd have expected that it's the other way around.\n",
    "\n",
    "## Extracted Path Statistics\n",
    "\n",
    "### Allowed Threshold = 0.3\n",
    "\n",
    "| Top Classes | Total Paths | Min Path Length | Max Path Length | Average Path Length | Median Path Length |\n",
    "| ----------- | ----------- | --------------- | --------------- | ------------------- | ------------------ |\n",
    "| 10          | 323,277     | 4               | 45              | 16.10               | 15                 |\n",
    "| 100         | 3,973,021   | 3               | 47              | 23.03               | 22                 |\n",
    "| 1000        | 17,421,062  | 3               | 48              | 24.12               | 23                 |\n",
    "| 10000       | 97,094,951  | 3               | 49              | 23.35               | 21                 |\n",
    "\n",
    "### Allowed Threshold = 0.4\n",
    "\n",
    "| Top Classes | Total Paths | Min Path Length | Max Path Length | Average Path Length | Median Path Length |\n",
    "| ----------- | ----------- | --------------- | --------------- | ------------------- | ------------------ |\n",
    "| 10          | 23,717      | 4               | 36              | 14.91               | 14                 |\n",
    "| 100         | 1,182,649   | 3               | 46              | 15.59               | 14                 |\n",
    "| 1000        | 4,752,482   | 3               | 47              | 17.27               | 16                 |\n",
    "| 10000       | 21,756,198  | 3               | 48              | 17.02               | 16                 |\n",
    "\n",
    "### Allowed Threshold = 0.5\n",
    "\n",
    "| Top Classes | Total Paths | Min Path Length | Max Path Length | Average Path Length | Median Path Length |\n",
    "| ----------- | ----------- | --------------- | --------------- | ------------------- | ------------------ |\n",
    "| 10          | 1,933       | 4               | 30              | 14.20               | 13                 |\n",
    "| 100         | 518,758     | 3               | 35              | 13.07               | 12                 |\n",
    "| 1000        | 1,981,464   | 3               | 41              | 14.26               | 13                 |\n",
    "| 10000       | 8,123,735   | 3               | 42              | 14.11               | 14                 |\n",
    "\n",
    "### Allowed Threshold = 0.6\n",
    "\n",
    "| Top Classes | Total Paths | Min Path Length | Max Path Length | Average Path Length | Median Path Length |\n",
    "| ----------- | ----------- | --------------- | --------------- | ------------------- | ------------------ |\n",
    "| 10          | 551         | 4               | 22              | 12.52               | 12                 |\n",
    "| 100         | 187,063     | 3               | 27              | 11.83               | 12                 |\n",
    "| 1000        | 685,543     | 3               | 32              | 12.85               | 12                 |\n",
    "| 10000       | 2,143,234   | 3               | 33              | 12.95               | 13                 |\n",
    "\n",
    "### Allowed Threshold = 0.7\n",
    "\n",
    "| Top Classes | Total Paths | Min Path Length | Max Path Length | Average Path Length | Median Path Length |\n",
    "| ----------- | ----------- | --------------- | --------------- | ------------------- | ------------------ |\n",
    "| 10          | 72          | 4               | 15              | 10.84               | 11                 |\n",
    "| 100         | 40,717      | 3               | 23              | 11.70               | 12                 |\n",
    "| 1000        | 192,028     | 3               | 28              | 12.57               | 12                 |\n",
    "| 10000       | 443,474     | 3               | 28              | 12.82               | 13                 |\n",
    "\n",
    "## Counting the number of `<DOWNWARD>` occurrences\n",
    "\n",
    "### Allowed Threshold = 0.3\n",
    "\n",
    "| Top Classes | Temperature | Min # `<DOWNWARD>` | Max # `<DOWNWARD>` | Avg # `<DOWNWARD>` | Median # `<DOWNWARD>` |\n",
    "| ----------- | ----------- | ------------------ | ------------------ | ------------------ | --------------------- |\n",
    "| **10**      | 0.5         | 7.00               | 48.00              | 18.94              | 11.00                 |\n",
    "| **10**      | 1.0         | 5.00               | 42.00              | 20.03              | 19.00                 |\n",
    "| **10**      | 1.5         | 2.00               | 42.00              | 16.30              | 12.00                 |\n",
    "| **100**     | 0.5         | 7.00               | 47.00              | 25.62              | 32.00                 |\n",
    "| **100**     | 1.0         | 6.00               | 44.00              | 19.80              | 16.00                 |\n",
    "| **100**     | 1.5         | 5.00               | 40.00              | 15.23              | 12.00                 |\n",
    "| **1000**    | 0.5         | 7.00               | 50.00              | 23.64              | 16.00                 |\n",
    "| **1000**    | 1.0         | 6.00               | 44.00              | 17.95              | 14.00                 |\n",
    "| **1000**    | 1.5         | 4.00               | 43.00              | 14.65              | 12.00                 |\n",
    "| **10000**   | 0.5         | 10.00              | 61.00              | 29.16              | 32.50                 |\n",
    "| **10000**   | 1.0         | 6.00               | 46.00              | 19.53              | 15.00                 |\n",
    "| **10000**   | 1.5         | 4.00               | 41.00              | 14.35              | 12.00                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Allowed Threshold = 0.4\n",
    "\n",
    "| Top Classes | Temperature | Min # `<DOWNWARD>` | Max # `<DOWNWARD>` | Avg # `<DOWNWARD>` | Median # `<DOWNWARD>` |\n",
    "| ----------- | ----------- | ------------------ | ------------------ | ------------------ | --------------------- |\n",
    "| **10**      | 0.5         | 6.00               | 72.00              | 13.06              | 10.00                 |\n",
    "| **10**      | 1.0         | 3.00               | 34.00              | 13.22              | 11.00                 |\n",
    "| **10**      | 1.5         | 2.00               | 30.00              | 12.13              | 11.00                 |\n",
    "| **100**     | 0.5         | 6.00               | 40.00              | 14.38              | 13.00                 |\n",
    "| **100**     | 1.0         | 6.00               | 34.00              | 14.13              | 13.00                 |\n",
    "| **100**     | 1.5         | 5.00               | 33.00              | 13.05              | 12.00                 |\n",
    "| **1000**    | 0.5         | 7.00               | 50.00              | 16.06              | 14.00                 |\n",
    "| **1000**    | 1.0         | 6.00               | 54.00              | 14.85              | 13.00                 |\n",
    "| **1000**    | 1.5         | 4.00               | 44.00              | 12.82              | 12.00                 |\n",
    "| **10000**   | 0.5         | 8.00               | 41.00              | 19.56              | 18.00                 |\n",
    "| **10000**   | 1.0         | 6.00               | 42.00              | 15.59              | 14.00                 |\n",
    "| **10000**   | 1.5         | 4.00               | 41.00              | 12.39              | 11.00                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Allowed Threshold = 0.5\n",
    "\n",
    "| Top Classes | Temperature | Min # `<DOWNWARD>` | Max # `<DOWNWARD>` | Avg # `<DOWNWARD>` | Median # `<DOWNWARD>` |\n",
    "| ----------- | ----------- | ------------------ | ------------------ | ------------------ | --------------------- |\n",
    "| **10**      | 0.5         | 9.00               | 25.00              | 10.41              | 10.00                 |\n",
    "| **10**      | 1.0         | 4.00               | 26.00              | 11.24              | 10.00                 |\n",
    "| **10**      | 1.5         | 0.00               | 28.00              | 8.39               | 8.00                  |\n",
    "| **100**     | 0.5         | 9.00               | 37.00              | 13.90              | 12.00                 |\n",
    "| **100**     | 1.0         | 6.00               | 33.00              | 12.59              | 12.00                 |\n",
    "| **100**     | 1.5         | 4.00               | 27.00              | 11.75              | 11.00                 |\n",
    "| **1000**    | 0.5         | 7.00               | 38.00              | 14.02              | 13.00                 |\n",
    "| **1000**    | 1.0         | 6.00               | 30.00              | 12.80              | 12.00                 |\n",
    "| **1000**    | 1.5         | 4.00               | 32.00              | 11.35              | 11.00                 |\n",
    "| **10000**   | 0.5         | 8.00               | 73.00              | 17.10              | 16.00                 |\n",
    "| **10000**   | 1.0         | 6.00               | 49.00              | 13.57              | 13.00                 |\n",
    "| **10000**   | 1.5         | 4.00               | 28.00              | 10.96              | 10.00                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Allowed Threshold = 0.6\n",
    "\n",
    "| Top Classes | Temperature | Min # `<DOWNWARD>` | Max # `<DOWNWARD>` | Avg # `<DOWNWARD>` | Median # `<DOWNWARD>` |\n",
    "| ----------- | ----------- | ------------------ | ------------------ | ------------------ | --------------------- |\n",
    "| **10**      | 0.5         | 7.00               | 65.00              | 10.67              | 11.00                 |\n",
    "| **10**      | 1.0         | 3.00               | 39.00              | 9.38               | 8.00                  |\n",
    "| **10**      | 1.5         | 0.00               | 23.00              | 4.94               | 4.00                  |\n",
    "| **100**     | 0.5         | 8.00               | 29.00              | 11.94              | 11.00                 |\n",
    "| **100**     | 1.0         | 5.00               | 25.00              | 11.22              | 11.00                 |\n",
    "| **100**     | 1.5         | 4.00               | 25.00              | 10.38              | 10.00                 |\n",
    "| **1000**    | 0.5         | 8.00               | 27.00              | 13.65              | 13.00                 |\n",
    "| **1000**    | 1.0         | 4.00               | 32.00              | 12.06              | 12.00                 |\n",
    "| **1000**    | 1.5         | 3.00               | 22.00              | 10.31              | 10.00                 |\n",
    "| **10000**   | 0.5         | 8.00               | 41.00              | 14.82              | 14.00                 |\n",
    "| **10000**   | 1.0         | 5.00               | 26.00              | 12.45              | 12.00                 |\n",
    "| **10000**   | 1.5         | 3.00               | 23.00              | 9.93               | 10.00                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Allowed Threshold = 0.7\n",
    "\n",
    "| Top Classes | Temperature | Min # `<DOWNWARD>` | Max # `<DOWNWARD>` | Avg # `<DOWNWARD>` | Median # `<DOWNWARD>` |\n",
    "| ----------- | ----------- | ------------------ | ------------------ | ------------------ | --------------------- |\n",
    "| **10**      | 0.5         | 7.00               | 32.00              | 9.05               | 8.00                  |\n",
    "| **10**      | 1.0         | 0.00               | 19.00              | 6.23               | 6.00                  |\n",
    "| **10**      | 1.5         | 2.00               | 28.00              | 11.53              | 11.00                 |\n",
    "| **100**     | 0.5         | 8.00               | 32.00              | 10.81              | 10.00                 |\n",
    "| **100**     | 1.0         | 5.00               | 21.00              | 10.51              | 10.00                 |\n",
    "| **100**     | 1.5         | 2.00               | 20.00              | 9.79               | 10.00                 |\n",
    "| **1000**    | 0.5         | 7.00               | 65.00              | 13.06              | 12.00                 |\n",
    "| **1000**    | 1.0         | 6.00               | 24.00              | 11.38              | 11.00                 |\n",
    "| **1000**    | 1.5         | 4.00               | 19.00              | 9.90               | 10.00                 |\n",
    "| **10000**   | 0.5         | 8.00               | 35.00              | 13.30              | 13.00                 |\n",
    "| **10000**   | 1.0         | 6.00               | 34.00              | 11.83              | 11.00                 |\n",
    "| **10000**   | 1.5         | 4.00               | 19.00              | 9.62               | 9.00                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count triples and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def load_triples(directory):\n",
    "    \"\"\"\n",
    "    Read all TSV files in the specified directory and build two mappings:\n",
    "    - child_to_parents: child -> list of parent classes (or instance classes)\n",
    "    - parent_to_children: parent -> list of subclasses (or entities)\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory containing TSV files.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (child_to_parents, parent_to_children)\n",
    "    \"\"\"\n",
    "    triple_count = 0\n",
    "    child_to_parents = defaultdict(list)\n",
    "    parent_to_children = defaultdict(list)\n",
    "    tsv_files = glob.glob(os.path.join(directory, \"*.tsv\"))\n",
    "    print(f\"Found {len(tsv_files)} TSV files in '{directory}'.\")\n",
    "\n",
    "    for filename in tqdm(tsv_files):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            header = f.readline()  # skip header line\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) != 3:\n",
    "                    continue\n",
    "                triple_count += 1\n",
    "                child, prop, parent = parts\n",
    "                child_to_parents[child].append(parent)\n",
    "                parent_to_children[parent].append(child)\n",
    "    print(f\"Loaded {triple_count} triples from '{directory}'.\")\n",
    "    return child_to_parents, parent_to_children\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Process P279 (subclass) data\n",
    "# ---------------------------\n",
    "child_to_parents_p279, parent_to_children_p279 = load_triples(\"P279\")\n",
    "print(\n",
    "    f\"\\nP279: Loaded {len(child_to_parents_p279)} child entities and {len(parent_to_children_p279)} parent entities.\\n\"\n",
    ")\n",
    "\n",
    "# Count nodes with multiple parents in P279\n",
    "multiple_parents_p279 = {\n",
    "    child: parents\n",
    "    for child, parents in tqdm(\n",
    "        child_to_parents_p279.items(), desc=\"P279: Counting multiple parents\"\n",
    "    )\n",
    "    if len(parents) > 1\n",
    "}\n",
    "print(\n",
    "    f\"P279: Nodes with multiple parents: {len(multiple_parents_p279)} out of {len(child_to_parents_p279)} children.\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "# Function to detect cycles (applied only on P279, where cycles in subclass relationships may occur)\n",
    "def find_cycles_full(child_to_parents):\n",
    "    \"\"\"\n",
    "    Detect cycles by performing DFS on the entire mapping.\n",
    "    Returns a list of cycles found.\n",
    "    \"\"\"\n",
    "    cycles = []\n",
    "    visited = set()\n",
    "\n",
    "    def dfs(node, path, local_visited):\n",
    "        if node in path:\n",
    "            cycles.append(path[path.index(node) :] + [node])\n",
    "            return\n",
    "        if node in local_visited:\n",
    "            return\n",
    "        local_visited.add(node)\n",
    "        for parent in child_to_parents.get(node, []):\n",
    "            dfs(parent, path + [node], local_visited)\n",
    "\n",
    "    for node in tqdm(child_to_parents.keys(), desc=\"P279: Finding cycles (full scan)\"):\n",
    "        if node not in visited:\n",
    "            local_visited = set()\n",
    "            dfs(node, [], local_visited)\n",
    "            visited.update(local_visited)\n",
    "    return cycles\n",
    "\n",
    "\n",
    "# Detect cycles in P279 data (full scan, not sampling)\n",
    "cycles_p279 = find_cycles_full(child_to_parents_p279)\n",
    "print(f\"\\nP279: Found {len(cycles_p279)} cycles in the data.\")\n",
    "\n",
    "\n",
    "# Count the number of triples for P31\n",
    "directory = \"./P31/\"\n",
    "triple_count = 0\n",
    "tsv_files = glob.glob(os.path.join(directory, \"*.tsv\"))\n",
    "print(f\"Found {len(tsv_files)} TSV files in '{directory}'.\")\n",
    "\n",
    "for filename in tqdm(tsv_files):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        header = f.readline()  # skip header line\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            triple_count += 1\n",
    "print(f\"Loaded {triple_count} triples from '{directory}'.\")\n",
    "\n",
    "\n",
    "# Count the number en_descriptions\n",
    "\n",
    "directory = \"./en_description/\"\n",
    "en_description_count = 0\n",
    "tsv_files = glob.glob(os.path.join(directory, \"*.tsv\"))\n",
    "print(f\"Found {len(tsv_files)} TSV files in '{directory}'.\")\n",
    "\n",
    "for filename in tqdm(tsv_files):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        header = f.readline()  # skip header line\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            en_description_count += 1\n",
    "print(f\"Loaded {en_description_count} en_descrioptions from '{directory}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 48.0, Average: 18.936, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 42.0, Average: 20.027, Median: 19.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 2.0, Max: 42.0, Average: 16.302, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=100, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 47.0, Average: 25.622, Median: 32.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=100, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 44.0, Average: 19.8, Median: 16.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=100, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 40.0, Average: 15.234, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=1000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 50.0, Average: 23.645, Median: 16.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=1000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 44.0, Average: 17.945, Median: 14.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=1000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 43.0, Average: 14.652, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 10.0, Max: 61.0, Average: 29.156, Median: 32.5\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 46.0, Average: 19.528, Median: 15.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [04:19<17:19, 259.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.3, num_classes=10000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.3/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 41.0, Average: 14.347, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 72.0, Average: 13.062, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 3.0, Max: 34.0, Average: 13.217, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 2.0, Max: 30.0, Average: 12.134, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-14250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=100, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 40.0, Average: 14.375, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-14250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=100, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 34.0, Average: 14.134, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-14250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=100, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 33.0, Average: 13.046, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-28750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=1000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 50.0, Average: 16.062, Median: 14.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-28750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=1000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 54.0, Average: 14.846, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-28750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=1000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 44.0, Average: 12.825, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 41.0, Average: 19.562, Median: 18.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 42.0, Average: 15.586, Median: 14.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [08:56<13:28, 269.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.4, num_classes=10000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.4/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 41.0, Average: 12.391, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 9.0, Max: 25.0, Average: 10.413, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 26.0, Average: 11.239, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 0.0, Max: 28.0, Average: 8.395, Median: 8.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-10250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=100, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 9.0, Max: 37.0, Average: 13.896, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-10250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=100, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 33.0, Average: 12.593, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-10250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=100, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 27.0, Average: 11.754, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=1000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 38.0, Average: 14.021, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=1000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 30.0, Average: 12.799, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=1000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 32.0, Average: 11.347, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 73.0, Average: 17.098, Median: 16.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 49.0, Average: 13.572, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [13:20<08:54, 267.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.5, num_classes=10000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.5/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 28.0, Average: 10.964, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 65.0, Average: 10.667, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 3.0, Max: 39.0, Average: 9.384, Median: 8.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 0.0, Max: 23.0, Average: 4.943, Median: 4.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=100, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 29.0, Average: 11.938, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=100, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 25.0, Average: 11.221, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=100, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 25.0, Average: 10.382, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-13250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=1000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 27.0, Average: 13.649, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-13250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=1000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 32.0, Average: 12.064, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-13250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=1000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 3.0, Max: 22.0, Average: 10.312, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-21750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 41.0, Average: 14.817, Median: 14.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-21750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 26.0, Average: 12.451, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-21750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [17:33<04:21, 261.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.6, num_classes=10000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.6/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 3.0, Max: 23.0, Average: 9.926, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 32.0, Average: 9.047, Median: 8.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 0.0, Max: 19.0, Average: 6.234, Median: 6.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/checkpoint-1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 2.0, Max: 28.0, Average: 11.531, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=100, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 32.0, Average: 10.813, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=100, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 5.0, Max: 21.0, Average: 10.505, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=100, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_100/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 2.0, Max: 20.0, Average: 9.788, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=1000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 7.0, Max: 65.0, Average: 13.061, Median: 12.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=1000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 24.0, Average: 11.383, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=1000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_1000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 19.0, Average: 9.9, Median: 10.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-12250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10000, temperature=0.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 8.0, Max: 35.0, Average: 13.301, Median: 13.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-12250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10000, temperature=1.0\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 6.0, Max: 34.0, Average: 11.833, Median: 11.0\n",
      "\n",
      "Tokenizer loaded from checkpoint.\n",
      "Special tokens: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<DOWNWARD>']}\n",
      "Model loaded from model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/checkpoint-12250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [21:38<00:00, 259.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: allowed_threshold=0.7, num_classes=10000, temperature=1.5\n",
      "Checkpoint used: model_output/allowed_threshold_0.7/model_size_small/loss_threshold_0.1/num_classes_10000/sample_first_batch_True/sampling_mode_class_aware/\n",
      "Min: 4.0, Max: 19.0, Average: 9.625, Median: 9.0\n",
      "\n",
      "\n",
      "## Counting the number of `<DOWNWARD>` occurrences\n",
      "\n",
      "Below are the min, max, average, and median occurrences of `<DOWNWARD>` in the generated sequences (across 1000 runs):\n",
      "\n",
      "### `allowed_threshold` = 0.3\n",
      "\n",
      "- `num_classes=10`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 48.00\n",
      "    - avg: 18.94\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 5.00\n",
      "    - max: 42.00\n",
      "    - avg: 20.03\n",
      "    - median: 19.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 2.00\n",
      "    - max: 42.00\n",
      "    - avg: 16.30\n",
      "    - median: 12.00\n",
      "\n",
      "- `num_classes=100`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 47.00\n",
      "    - avg: 25.62\n",
      "    - median: 32.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 44.00\n",
      "    - avg: 19.80\n",
      "    - median: 16.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 5.00\n",
      "    - max: 40.00\n",
      "    - avg: 15.23\n",
      "    - median: 12.00\n",
      "\n",
      "- `num_classes=1000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 50.00\n",
      "    - avg: 23.64\n",
      "    - median: 16.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 44.00\n",
      "    - avg: 17.95\n",
      "    - median: 14.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 43.00\n",
      "    - avg: 14.65\n",
      "    - median: 12.00\n",
      "\n",
      "- `num_classes=10000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 10.00\n",
      "    - max: 61.00\n",
      "    - avg: 29.16\n",
      "    - median: 32.50\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 46.00\n",
      "    - avg: 19.53\n",
      "    - median: 15.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 41.00\n",
      "    - avg: 14.35\n",
      "    - median: 12.00\n",
      "\n",
      "### `allowed_threshold` = 0.4\n",
      "\n",
      "- `num_classes=10`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 6.00\n",
      "    - max: 72.00\n",
      "    - avg: 13.06\n",
      "    - median: 10.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 3.00\n",
      "    - max: 34.00\n",
      "    - avg: 13.22\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 2.00\n",
      "    - max: 30.00\n",
      "    - avg: 12.13\n",
      "    - median: 11.00\n",
      "\n",
      "- `num_classes=100`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 6.00\n",
      "    - max: 40.00\n",
      "    - avg: 14.38\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 34.00\n",
      "    - avg: 14.13\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 5.00\n",
      "    - max: 33.00\n",
      "    - avg: 13.05\n",
      "    - median: 12.00\n",
      "\n",
      "- `num_classes=1000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 50.00\n",
      "    - avg: 16.06\n",
      "    - median: 14.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 54.00\n",
      "    - avg: 14.85\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 44.00\n",
      "    - avg: 12.82\n",
      "    - median: 12.00\n",
      "\n",
      "- `num_classes=10000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 41.00\n",
      "    - avg: 19.56\n",
      "    - median: 18.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 42.00\n",
      "    - avg: 15.59\n",
      "    - median: 14.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 41.00\n",
      "    - avg: 12.39\n",
      "    - median: 11.00\n",
      "\n",
      "### `allowed_threshold` = 0.5\n",
      "\n",
      "- `num_classes=10`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 9.00\n",
      "    - max: 25.00\n",
      "    - avg: 10.41\n",
      "    - median: 10.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 4.00\n",
      "    - max: 26.00\n",
      "    - avg: 11.24\n",
      "    - median: 10.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 0.00\n",
      "    - max: 28.00\n",
      "    - avg: 8.39\n",
      "    - median: 8.00\n",
      "\n",
      "- `num_classes=100`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 9.00\n",
      "    - max: 37.00\n",
      "    - avg: 13.90\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 33.00\n",
      "    - avg: 12.59\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 27.00\n",
      "    - avg: 11.75\n",
      "    - median: 11.00\n",
      "\n",
      "- `num_classes=1000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 38.00\n",
      "    - avg: 14.02\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 30.00\n",
      "    - avg: 12.80\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 32.00\n",
      "    - avg: 11.35\n",
      "    - median: 11.00\n",
      "\n",
      "- `num_classes=10000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 73.00\n",
      "    - avg: 17.10\n",
      "    - median: 16.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 49.00\n",
      "    - avg: 13.57\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 28.00\n",
      "    - avg: 10.96\n",
      "    - median: 10.00\n",
      "\n",
      "### `allowed_threshold` = 0.6\n",
      "\n",
      "- `num_classes=10`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 65.00\n",
      "    - avg: 10.67\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 3.00\n",
      "    - max: 39.00\n",
      "    - avg: 9.38\n",
      "    - median: 8.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 0.00\n",
      "    - max: 23.00\n",
      "    - avg: 4.94\n",
      "    - median: 4.00\n",
      "\n",
      "- `num_classes=100`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 29.00\n",
      "    - avg: 11.94\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 5.00\n",
      "    - max: 25.00\n",
      "    - avg: 11.22\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 25.00\n",
      "    - avg: 10.38\n",
      "    - median: 10.00\n",
      "\n",
      "- `num_classes=1000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 27.00\n",
      "    - avg: 13.65\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 4.00\n",
      "    - max: 32.00\n",
      "    - avg: 12.06\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 3.00\n",
      "    - max: 22.00\n",
      "    - avg: 10.31\n",
      "    - median: 10.00\n",
      "\n",
      "- `num_classes=10000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 41.00\n",
      "    - avg: 14.82\n",
      "    - median: 14.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 5.00\n",
      "    - max: 26.00\n",
      "    - avg: 12.45\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 3.00\n",
      "    - max: 23.00\n",
      "    - avg: 9.93\n",
      "    - median: 10.00\n",
      "\n",
      "### `allowed_threshold` = 0.7\n",
      "\n",
      "- `num_classes=10`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 32.00\n",
      "    - avg: 9.05\n",
      "    - median: 8.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 0.00\n",
      "    - max: 19.00\n",
      "    - avg: 6.23\n",
      "    - median: 6.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 2.00\n",
      "    - max: 28.00\n",
      "    - avg: 11.53\n",
      "    - median: 11.00\n",
      "\n",
      "- `num_classes=100`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 32.00\n",
      "    - avg: 10.81\n",
      "    - median: 10.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 5.00\n",
      "    - max: 21.00\n",
      "    - avg: 10.51\n",
      "    - median: 10.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 2.00\n",
      "    - max: 20.00\n",
      "    - avg: 9.79\n",
      "    - median: 10.00\n",
      "\n",
      "- `num_classes=1000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 7.00\n",
      "    - max: 65.00\n",
      "    - avg: 13.06\n",
      "    - median: 12.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 24.00\n",
      "    - avg: 11.38\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 19.00\n",
      "    - avg: 9.90\n",
      "    - median: 10.00\n",
      "\n",
      "- `num_classes=10000`:\n",
      "  - for `temperature=0.5`:\n",
      "    - min: 8.00\n",
      "    - max: 35.00\n",
      "    - avg: 13.30\n",
      "    - median: 13.00\n",
      "  - for `temperature=1.0`:\n",
      "    - min: 6.00\n",
      "    - max: 34.00\n",
      "    - avg: 11.83\n",
      "    - median: 11.00\n",
      "  - for `temperature=1.5`:\n",
      "    - min: 4.00\n",
      "    - max: 19.00\n",
      "    - avg: 9.62\n",
      "    - median: 9.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "import numpy as np\n",
    "\n",
    "def get_latest_checkpoint_dir(base_dir):\n",
    "    # List all subdirectories that match the pattern \"checkpoint-XXX\"\n",
    "    checkpoint_dirs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"checkpoint-\")\n",
    "    ]\n",
    "    if not checkpoint_dirs:\n",
    "        return None\n",
    "    # Sort the directories by the numeric portion after \"checkpoint-\"\n",
    "    checkpoint_dirs.sort(key=lambda d: int(d.split(\"-\")[-1]))\n",
    "    latest_checkpoint = checkpoint_dirs[-1]\n",
    "    return os.path.join(base_dir, latest_checkpoint)\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path: str) -> GPT2Tokenizer:\n",
    "    \"\"\"\n",
    "    Load a GPT-2 tokenizer from the specified checkpoint path.\n",
    "    \"\"\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    print(\"Tokenizer loaded from checkpoint.\")\n",
    "    print(f\"Special tokens: {tokenizer.special_tokens_map}\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def load_model(checkpoint_dir: str, tokenizer: GPT2Tokenizer, force_device=\"cpu\") -> tuple:\n",
    "    \"\"\"\n",
    "    Load a GPT-2 model from a checkpoint and prepare it for inference.\n",
    "    \"\"\"\n",
    "    config = GPT2Config.from_pretrained(checkpoint_dir)\n",
    "    model = GPT2LMHeadModel.from_pretrained(checkpoint_dir, config=config)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    device = torch.device(force_device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {checkpoint_dir}\")\n",
    "    return model, device\n",
    "\n",
    "# Set parameters as variables.\n",
    "tokenizer_path = \"./custom_tokenizer\"  # Path to your custom tokenizer.\n",
    "num_sequences = 1000  # Number of sequences to generate\n",
    "model_size = \"small\"\n",
    "loss_threshold = 0.1\n",
    "top_p = 0.9\n",
    "force_device = \"cuda\"\n",
    "max_length = 256\n",
    "\n",
    "# Create a nested dictionary to store the results (stats).\n",
    "results = {}\n",
    "\n",
    "for allowed_threshold in tqdm([0.3, 0.4, 0.5, 0.6, 0.7]):\n",
    "    results[allowed_threshold] = {}\n",
    "    for num_classes in [10, 100, 1000, 10000]:\n",
    "        results[allowed_threshold][num_classes] = {}\n",
    "        for temperature in [0.5, 1.0, 1.5]:\n",
    "            # Construct the checkpoint directory path.\n",
    "            checkpoint_dir = (\n",
    "                f\"model_output/allowed_threshold_{allowed_threshold:.1f}/\"\n",
    "                f\"model_size_{model_size}/loss_threshold_{loss_threshold:.1f}/\"\n",
    "                f\"num_classes_{num_classes}/\"\n",
    "                f\"sample_first_batch_True/\"\n",
    "                f\"sampling_mode_class_aware/\"\n",
    "            )\n",
    "\n",
    "            tokenizer = load_tokenizer(tokenizer_path)\n",
    "\n",
    "            latest_checkpoint_dir = get_latest_checkpoint_dir(checkpoint_dir)\n",
    "            if latest_checkpoint_dir is not None:\n",
    "                model, device = load_model(latest_checkpoint_dir, tokenizer, force_device=force_device)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"No checkpoint found in {checkpoint_dir}.\")\n",
    "\n",
    "            # Prepare the prompt.\n",
    "            prompt = \"<BOS>\"\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            # Generate sequences.\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                do_sample=True,\n",
    "                top_p=top_p,\n",
    "                temperature=temperature,\n",
    "                num_return_sequences=num_sequences,\n",
    "            )\n",
    "\n",
    "            # Count occurrences of \"<DOWNWARD>\" in each generated sequence.\n",
    "            len_paths = []\n",
    "            for output in outputs:\n",
    "                text = tokenizer.decode(output, skip_special_tokens=False)\n",
    "                len_paths.append(text.count(\"<DOWNWARD>\"))\n",
    "\n",
    "            # Compute statistics.\n",
    "            min_count = float(np.min(len_paths))\n",
    "            max_count = float(np.max(len_paths))\n",
    "            avg_count = float(np.mean(len_paths))\n",
    "            median_count = float(np.median(len_paths))\n",
    "\n",
    "            # Store stats in the results dictionary.\n",
    "            results[allowed_threshold][num_classes][temperature] = {\n",
    "                \"min\": min_count,\n",
    "                \"max\": max_count,\n",
    "                \"avg\": avg_count,\n",
    "                \"median\": median_count,\n",
    "            }\n",
    "\n",
    "            print(f\"Processed: allowed_threshold={allowed_threshold}, num_classes={num_classes}, temperature={temperature}\")\n",
    "            print(f\"Checkpoint used: {checkpoint_dir}\")\n",
    "            print(\n",
    "                f\"Min: {min_count}, Max: {max_count}, \"\n",
    "                f\"Average: {avg_count}, Median: {median_count}\\n\"\n",
    "            )\n",
    "\n",
    "# Now, print the results in a markdown-friendly format.\n",
    "print(\"\\n## Counting the number of `<DOWNWARD>` occurrences\\n\")\n",
    "print(\"Below are the min, max, average, and median occurrences of `<DOWNWARD>` in the generated sequences \"\n",
    "      f\"(across {num_sequences} runs):\\n\")\n",
    "\n",
    "for allowed_threshold in sorted(results.keys()):\n",
    "    print(f\"### `allowed_threshold` = {allowed_threshold}\\n\")\n",
    "    for num_classes in sorted(results[allowed_threshold].keys()):\n",
    "        print(f\"- `num_classes={num_classes}`:\")\n",
    "        for temperature in sorted(results[allowed_threshold][num_classes].keys()):\n",
    "            stats = results[allowed_threshold][num_classes][temperature]\n",
    "            print(f\"  - for `temperature={temperature}`:\")\n",
    "            print(f\"    - min: {stats['min']:.2f}\")\n",
    "            print(f\"    - max: {stats['max']:.2f}\")\n",
    "            print(f\"    - avg: {stats['avg']:.2f}\")\n",
    "            print(f\"    - median: {stats['median']:.2f}\")\n",
    "        print(\"\")  # Extra newline for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.6487212707001282), np.float64(1.1051709180756477))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(0.5),np.exp(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6065306597126334), np.float64(0.9048374180359595))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / np.exp(0.5), 1/ np.exp(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.6487212707001282), np.float64(1.1051709180756477))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.5),np.exp(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-python3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
